{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- why feature inversion\n",
    "- the simple case: griffin-lim\n",
    "- derived features:\n",
    "    - mel spectrogram\n",
    "    - mfcc\n",
    "- constant-q griffin-lim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral features\n",
    "\n",
    "Many of the audio features computed in librosa --- Mel spectrograms, MFCCs, etc --- follow this generic pattern:\n",
    "\n",
    "1. Convert audio signal $y \\in \\mathbb{R}^N$ to a short-time Fourier transform representation $D \\in \\mathbb{C}^{F \\times T}$ for $F = 1 + N_{FFT} / 2$ frequency bins.\n",
    "2. Discard phase information from $D$, leaving only the spectral magnitudes $S = |D| \\in \\mathbb{R}_+^{F \\times T}$\n",
    "3. Project the frequency axis onto a lower-dimensional subspace (e.g. Mel frequencies or chroma/pitch classes): $X = WS$ where $W \\in \\mathbb{R}^{d \\times F}$ is the transformation basis.\n",
    "4. Additional post-processing or normalization (e.g. decibel scaling).\n",
    "\n",
    "In short, we have a chain of steps $y \\rightarrow D \\rightarrow S \\rightarrow X \\rightarrow ...$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
